1. In the vacuum cleaner domain in part 1, what were the states and actions? 
What is the branching factor?
	The different states are the squares the vacuum agent could be standing at, each of the squares can contain dirt or no dirt and can contain agent or no agent.
	Actions involved moving in all directions and sucking just a bit different 
	from lab1. With other words, turning doesnt cost anything. 
	To find the childs of each node we try to go west, north, east and south
	from each position, therefore we can state that the solutionspace has a branching factor of 4.

2. What is the difference between Breadth First Search and Uniform Cost Search 
in a domain where the cost of each action is 1?
	The only difference is one condition, "if the node already is added for 
	being searched and we recently found a node with lower cost to it, replace
	the old node". When executing this code there will be no actual difference
	other than execution time as breadth-first already finds shortest paths to
	everything around it.

3. Suppose that h1 and h2 are admissible heuristics (used in for example A*). 
Which of the following are also admissible?
a) (h1+h2)/2
	Yup, since we will end up between two admissible values, the value we get
	must still be admissible.
b) 2h1
	Nope, if h1 finds the optimal cost, then 2h1 clearly overestimates the cost.
c) max (h1,h2)
	Yup, h1 and h2 both doesnt overestimate the path, with other words, taking 
	the bigger of them just makes the result the closest to the actual value.

4. If one would use A* to search for a path to one specific square in the vacuum 
domain, what could the heuristic (h) be? The cost function (g)? Is it an 
admissible heuristic?
	The easiest heuristic for (h) would be to use the straight-line distance, which, due to the general triangle inequality, will always be an underestimation; and therefore be admissable. The cost function (g) would be the cost of the actual distance to the root node.

5. Draw and explain. Choose your three favorite search algorithms and apply them
 to any problem domain (it might be a good idea to use a domain where you can 
identify a good heuristic function). Draw the search tree for them, and explain 
how they proceed in the searching. Also include the memory usage. You can attach 
a hand-made drawing.
	Check search_algorithm.jpg (and hopefully you can read it, otherwise send a 
	mail and we will try to make it better). 

	Depth-first can use the least 
	memory as we can save the iterations in the loop-structure, with other words
	we only need to remember what way we have taken so far. With breadth first
	we need to have all the leaves in the last iteration, meaning we need to
	save the nodes in an external structure. If the leaves are at different 
	levels it will use less memory than if all leaves are the the lowest level 
	of the tree. Dijkstras which is a special case of A* is a lot different. 
	Here we need one slot for each node to remember which was the cheapest route
	to that node. This also makes it easy for us and say that Dijkstras use O(N)
	memory.

	dijkstras
	Breadth-first
	Depth-first

	

6. Look at all the offline search algorithms presented in chapter 3 plus A* 
search. Are they complete? Are they optimal? Explain why!
	Complete: If a solution exists, it will be found
	Optimal: The best solution is found
	Offline Search algorithms: Computes a complete solution before starting
	
Search Algorithms		Complete				Optimal
A*				Yes					Yes
Breadth-first			Yes, if finite branching factor		If uniform cost
Depth-first			Yes, if in finite space			No
Uniform cost			Yes, if finite branching factor		Yes
Depth-limited			No					No
Iterative deepening depth-first	Yes, if in finite space			Yes, when path cost is non-decreasing
Bi-directional (Breadth-first)	Yes, if finite branching factor		If uniform cost
	
A*: Continues to explore till the solution is found, therefore complete. As the algorithm progresses it will eventually find the an optimal solution, even if variants where an optimum isn't guaranteed, but the search will be a lot faster.
Breadth-first: Always explores the most shallow node, thus the first solution found will be optimal. Complete due to continuing expanding till the searchspace is covered
Depth-first: Explores the deepest node, a solution is often found fast, but it's often subuptimal. covers the entire search space in time, therefore complete.
Uniform cost: Basically a modified version of the breadth-first search, therefore similar properties.
Dept-limited: A hard limit might prevent a solution from ever being found, and like the depth-first search no optimal solution can be guaranteed.
Iterative deepening: This algorithm can be seen as a combination of breadth first and depth first algorithm; due to the iterative deepening the first solution found will be optimal; and since it eventually covers all of the search space it's complete.
Bi-directional (Breadth-first): This eventually coveres all of the searchspace. Since it's basically an adaptation of the breatdh first search, the solution will be optimal.

7. Assume that you had to go back and do lab 1 once more, but this time with 
obstacles. Remember that the agent did not have perfect knowledge of the 
environment but had to explore it incrementally. Could you still use the search 
algorithms you have learned to guide the agent's execution? What would you 
search for? Give an example.
	Yes we could use search algorithms to find the cheapest road to a non-observed
	square. We can also use search algorithms to find the cheapest route that 
	visits all squares in a certain area. The best would be to combine these 
	in some way, so that we find a path to the square with the cheapest covering
	route. This means we should have a greedy kind of breadth-first search that
	when we
